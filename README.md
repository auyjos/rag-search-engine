# RAG Search Engine

A comprehensive information retrieval system implementing multiple search methodologies including keyword-based search (BM25), semantic search, and hybrid search approaches. Built as a learning project to understand the fundamentals of Retrieval-Augmented Generation (RAG) systems.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
  - [Keyword Search](#keyword-search)
  - [Semantic Search](#semantic-search)
  - [Hybrid Search](#hybrid-search)
- [How It Works](#how-it-works)
- [Project Structure](#project-structure)
- [Configuration](#configuration)

## ğŸ¯ Overview

This project demonstrates the core concepts behind modern search systems by implementing and comparing different search approaches:

- **Keyword Search**: Traditional BM25 (Best Matching 25) algorithm for exact and fuzzy keyword matching
- **Semantic Search**: Neural embedding-based search that understands meaning and context
- **Hybrid Search**: Combines keyword and semantic approaches with configurable weighting

The system is built around a dataset of ~5,000 movies, providing a rich corpus for search experimentation.

## âœ¨ Features

### Search Methods

1. **BM25 Keyword Search**
   - Inverted index construction
   - TF-IDF scoring with length normalization
   - Stopword filtering
   - Configurable k1 and b parameters

2. **Semantic Search**
   - Document-level embeddings using Sentence Transformers
   - Chunk-level search for long documents
   - Cosine similarity scoring
   - Sentence-aware chunking with overlap

3. **Hybrid Search**
   - Min-max score normalization
   - Weighted combination of BM25 and semantic scores
   - Configurable alpha parameter (0.0 = pure semantic, 1.0 = pure keyword)
   - Best of both worlds: handles exact matches and conceptual queries

### Additional Features

- **Caching**: Embeddings and indexes are cached for performance
- **Chunking**: Smart text chunking with sentence boundaries and overlap
- **CLI Tools**: Easy-to-use command-line interfaces for all search methods
- **Extensible**: Modular design for adding new search methods

## ğŸš€ Installation

### Prerequisites

- Python 3.12 or higher
- [uv](https://github.com/astral-sh/uv) (recommended) or pip

### Setup

```bash
# Clone the repository
git clone https://github.com/auyjos/rag-search-engine.git
cd rag-search-engine

# Install dependencies with uv
uv sync

# Or with pip
pip install -r requirements.txt
```

The first time you run semantic search, it will download the sentence-transformer model (~80MB).

## ğŸ’» Usage

### Keyword Search

Search using BM25 algorithm for exact keyword matching:

```bash
# Build the inverted index (first time only)
uv run cli/keyword_search_cli.py build

# Search for movies
uv run cli/keyword_search_cli.py search "space adventure"

# Search with limit
uv run cli/keyword_search_cli.py search "detective mystery" --limit 10

# Get BM25 IDF score for a term
uv run cli/keyword_search_cli.py idf "detective"

# Get BM25 TF score for a document and term
uv run cli/keyword_search_cli.py tf 123 "detective"

# Run BM25 search with custom parameters
uv run cli/keyword_search_cli.py bm25 "space adventure" --limit 5
```

### Semantic Search

Search by meaning using neural embeddings:

```bash
# Generate embeddings (first time or when data changes)
uv run cli/semantic_search_cli.py embed-chunks

# Document-level semantic search
uv run cli/semantic_search_cli.py search "movies about family relationships"

# Chunk-level semantic search (better for long documents)
uv run cli/semantic_search_cli.py search-chunked "robot falls in love" --limit 10

# Create semantic chunks from text
uv run cli/semantic_search_cli.py chunk "Long text..." --max-chunk-size 4 --overlap 1
```

### Hybrid Search

Combine keyword and semantic approaches:

```bash
# Normalize scores (utility function)
uv run cli/hybrid_search_cli.py normalize 0.5 2.3 1.2 0.5 0.1

# Weighted hybrid search with default alpha (0.5)
uv run cli/hybrid_search_cli.py weighted-search "British detective"

# Emphasize keywords (alpha=0.8 means 80% keyword, 20% semantic)
uv run cli/hybrid_search_cli.py weighted-search "The Revenant" --alpha 0.8 --limit 10

# Emphasize semantics (alpha=0.2 means 20% keyword, 80% semantic)
uv run cli/hybrid_search_cli.py weighted-search "family movies" --alpha 0.2 --limit 10

# Balanced approach
uv run cli/hybrid_search_cli.py weighted-search "2015 comedies" --alpha 0.5 --limit 10
```

### Alpha Parameter Guide

The alpha (Î±) parameter controls the balance between keyword and semantic search:

| Alpha | Distribution | Best For | Example |
|-------|--------------|----------|---------|
| 1.0 | 100% Keyword | Exact titles, names, IDs | "The Revenant" |
| 0.8 | 80% Keyword, 20% Semantic | Specific terms with some context | "Leonardo DiCaprio survival" |
| 0.5 | 50/50 Split | Balanced queries | "2015 adventure films" |
| 0.2 | 20% Keyword, 80% Semantic | Conceptual searches | "movies about redemption" |
| 0.0 | 100% Semantic | Abstract concepts | "finding yourself" |

## ğŸ”§ How It Works

### BM25 Keyword Search

1. **Indexing**: Builds an inverted index mapping terms to documents
2. **Scoring**: Uses BM25 formula: `score = IDF(term) Ã— TF(term, doc)`
   - **IDF**: Inverse Document Frequency - rarer terms score higher
   - **TF**: Term Frequency with length normalization
3. **Ranking**: Returns top documents by BM25 score

### Semantic Search

1. **Embedding Generation**: Converts text to 384-dimensional vectors using `all-MiniLM-L6-v2`
2. **Chunking**: Splits long documents into overlapping chunks at sentence boundaries
3. **Similarity**: Computes cosine similarity between query and document embeddings
4. **Aggregation**: For chunk-based search, keeps the maximum score per document

### Hybrid Search

1. **Parallel Search**: Runs both BM25 and semantic search simultaneously
2. **Normalization**: Applies min-max normalization to make scores comparable
3. **Combination**: Calculates weighted score: `Î± Ã— BM25_norm + (1-Î±) Ã— semantic_norm`
4. **Ranking**: Returns documents sorted by hybrid score

## ğŸ“ Project Structure

```
rag-search-engine/
â”œâ”€â”€ cli/                          # Command-line interfaces
â”‚   â”œâ”€â”€ keyword_search_cli.py     # BM25 search CLI
â”‚   â”œâ”€â”€ semantic_search_cli.py    # Semantic search CLI
â”‚   â”œâ”€â”€ hybrid_search_cli.py      # Hybrid search CLI
â”‚   â”œâ”€â”€ classes/                  # Core search implementations
â”‚   â”‚   â”œâ”€â”€ base_search.py        # Base semantic search class
â”‚   â”‚   â”œâ”€â”€ chunk_search.py       # Chunk-level semantic search
â”‚   â”‚   â”œâ”€â”€ document_search.py    # Document-level semantic search
â”‚   â”‚   â”œâ”€â”€ hybrid_search.py      # Hybrid search implementation
â”‚   â”‚   â”œâ”€â”€ invert_index.py       # Inverted index & BM25
â”‚   â”‚   â””â”€â”€ semantic_search.py    # Legacy compatibility layer
â”‚   â”œâ”€â”€ commands/                 # Command handlers
â”‚   â”‚   â”œâ”€â”€ embedding_commands.py # Embedding generation commands
â”‚   â”‚   â””â”€â”€ search_commands.py    # Search commands
â”‚   â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”‚   â”œâ”€â”€ cache.py              # Caching for embeddings
â”‚   â”‚   â”œâ”€â”€ chunking.py           # Text chunking utilities
â”‚   â”‚   â””â”€â”€ similarity.py         # Similarity calculations
â”‚   â””â”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ data/                         # Data files
â”‚   â”œâ”€â”€ movies.json               # Movie dataset (~5,000 movies)
â”‚   â””â”€â”€ stopwords.txt             # Stopwords for keyword search
â”œâ”€â”€ helpers/                      # Helper modules
â”‚   â”œâ”€â”€ constants.py              # BM25 constants
â”‚   â””â”€â”€ tokenizer.py              # Text tokenization
â”œâ”€â”€ cache/                        # Generated cache files
â”‚   â”œâ”€â”€ chunk_embeddings.npy      # Cached chunk embeddings
â”‚   â”œâ”€â”€ chunk_metadata.json       # Chunk metadata
â”‚   â”œâ”€â”€ index.pkl                 # Inverted index
â”‚   â””â”€â”€ ...                       # Other cache files
â””â”€â”€ pyproject.toml                # Project configuration
```

## âš™ï¸ Configuration

Key configuration values in [`cli/config.py`](cli/config.py):

```python
# Model
DEFAULT_MODEL = "all-MiniLM-L6-v2"  # Sentence transformer model

# Chunking
DEFAULT_CHUNK_SIZE = 4              # Sentences per chunk
DEFAULT_OVERLAP = 1                 # Overlapping sentences

# Search
DEFAULT_SEARCH_LIMIT = 5            # Default number of results
SCORE_PRECISION = 4                 # Decimal places for scores

# BM25 (in helpers/constants.py)
BM25_K1 = 1.5                       # Term saturation parameter
BM25_B = 0.75                       # Length normalization parameter
```

## ğŸ“ Learning Objectives

This project demonstrates:

- **Information Retrieval**: Traditional IR techniques (inverted index, TF-IDF, BM25)
- **Neural Search**: Embedding generation, vector similarity, semantic understanding
- **Hybrid Systems**: Combining multiple approaches, score normalization
- **RAG Foundations**: Core concepts needed for Retrieval-Augmented Generation
- **Python Best Practices**: Modular design, CLI tools, caching strategies

## ğŸ¤ Contributing

This is a learning project, but contributions are welcome! Feel free to:

- Report bugs or issues
- Suggest improvements
- Add new search methods
- Improve documentation

## ğŸ“ License

This project is available for educational purposes.

## ğŸ™ Acknowledgments

- Dataset: Movie descriptions from various sources
- Model: [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) by Sentence Transformers
- Inspiration: Modern RAG systems and information retrieval techniques
